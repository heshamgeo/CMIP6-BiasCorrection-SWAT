{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['R_HOME'] = \"C:/Program Files/R/R-4.4.1\"  # Adjust if needed\n",
    "os.environ['R_USER'] = \"C:/Users/hhp1483/Documents/R/win-library/4.4\"\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "print(ro.r('version'))  # Should now show R 4.4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e632c2",
   "metadata": {},
   "source": [
    "### **Return Period Analysis and Data Preparation**\n",
    "#### **Overview**\n",
    "This step initializes the return period analysis by importing necessary libraries and defining the paths for the **Annual Maximum Series (AMS)** datasets. The AMS data includes **historical observations** and **future projections** under two climate scenarios (SSP2-4.5 and SSP5-8.5). \n",
    "\n",
    "The framework ensures that all datasets are correctly formatted and available for further statistical analysis.\n",
    "\n",
    "\n",
    "\n",
    "#### **Steps Performed**\n",
    "1. **Import Required Libraries**\n",
    "   - **rpy2 & lmom R Package:** For L-moment calculations and probability distribution fitting.\n",
    "\n",
    "2. **Define Paths for AMS Data**\n",
    "   - Specifies the **file paths** for:\n",
    "     - **Observed AMS data**\n",
    "     - **Future AMS projections** under **SSP2-4.5 and SSP5-8.5**\n",
    "   - Uses a **structured directory format** to maintain consistency in data storage.\n",
    "\n",
    "3. **Scenario Mapping**\n",
    "   - Maps the climate scenarios **(SSP2-4.5 → `ssp245`, SSP5-8.5 → `ssp585`)** to their corresponding **model filenames**.\n",
    "\n",
    "#### **Instructions for Use**\n",
    "- Ensure that all AMS CSV files exist in the **specified directory (`E:/Projection_SWAT/ScenarioSs_SWAT_/AMS_Final/`)**.\n",
    "- Verify that the file naming conventions are **consistent** with the script.\n",
    "- The observed and future AMS datasets should be structured with **columns labeled \"Year\" and \"AMS\"**.\n",
    "\n",
    "\n",
    "\n",
    "#### **Expected Output**\n",
    "- **Correctly loaded AMS datasets** for both historical observations and future projections.\n",
    "- **Scenario mapping completed**, linking models to the appropriate SSP climate scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3d0d5b-dc54-4e0b-a914-834d5541d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearson3 as pe3\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from glob import glob\n",
    "import os\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import default_converter\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "rlmom = importr('lmom')\n",
    "\n",
    "path = r'D:/CMIP6-BiasCorrection-SWAT/workingfolder/AMS'\n",
    "pattern = os.path.join(path, '*.csv')\n",
    "csv_files = glob(pattern)\n",
    "\n",
    "print(csv_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bc3e6-590c-49c8-865e-4c4e41014b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Fitting Probability Distributions to Historical AMS Data (21th)**\n",
    "#### **Overview**\n",
    "This step applies **L-Moments methods** to the **observed Annual Maximum Series (AMS) dataset** to determine the best-fitting probability distribution. Several candidate distributions are tested, including **Log-Pearson III (LP3), Generalized Extreme Value (GEV), Pearson III (PE3), Log-Normal (LN3), Generalized Pareto (GPA), and Gumbel (GUM)**.\n",
    "\n",
    "The return period curves for each distribution are plotted to visually compare their fits, helping us identify the most suitable distribution for historical streamflow data.\n",
    "\n",
    "\n",
    "\n",
    "#### **Steps Performed**\n",
    "1. **Load Historical AMS Data**\n",
    "   - Reads the **observed AMS dataset** from the defined CSV file.\n",
    "   - Converts the **\"Year\"** column to a datetime format and ensures correct indexing.\n",
    "\n",
    "2. **Compute L-Moments**\n",
    "   - Uses the **lmoments R package** via `rpy2` to compute L-Moments for the observed AMS data.\n",
    "   - Applies the **L-Moments method** to estimate distribution parameters.\n",
    "\n",
    "3. **Fit Multiple Probability Distributions**\n",
    "   - Fits the following **six probability distributions** using L-Moments:\n",
    "     - **Log-Pearson III (LP3)**\n",
    "     - **Generalized Extreme Value (GEV)**\n",
    "     - **Pearson Type III (PE3)**\n",
    "     - **Log-Normal (LN3)**\n",
    "     - **Generalized Pareto (GPA)**\n",
    "     - **Gumbel (GUM)**\n",
    "   - Extracts distribution parameters and computes return period estimates.\n",
    "\n",
    "4. **Plot Return Period Curves**\n",
    "   - Creates a **log-scale return period plot** comparing all distributions.\n",
    "   - Includes **5-year to 200-year return periods**.\n",
    "   - Highlights observed AMS data points.\n",
    "\n",
    "5. **Determine the Best-Fitting Distribution**\n",
    "   - Compares the **fitted return period curves** to observed data.\n",
    "   - Identifies the best-fit distribution based on **visual agreement** and **statistical accuracy**.\n",
    "\n",
    "\n",
    "\n",
    "#### **Instructions for Use**\n",
    "- Ensure that the **lmoments R package** is installed and accessible via `rpy2`.\n",
    "- Verify that the observed AMS data is correctly formatted (`\"Year\"` column as datetime and `\"AMS\"` as float values).\n",
    "- The generated plot will visually compare different distributions for further analysis.\n",
    "\n",
    "\n",
    "\n",
    "#### **Expected Output**\n",
    "- **L-Moments parameter estimates** for each tested distribution.\n",
    "- **A return period curve plot** displaying all fitted distributions alongside observed AMS data.\n",
    "- **Identification of the best-fitting distribution** for historical streamflow analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43109175-deff-489d-ab8f-f06006b78aa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (LogPearson-III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc4298-f05a-4c88-b82e-13a982b5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Observed AMS Data\n",
    "ams_hist = pd.read_csv(f\"{path}/observed_ams.csv\")\n",
    "ams_hist = ams_hist['AMS'].values.reshape(-1, 1)\n",
    "\n",
    "# Create an Empty Array to Store Results\n",
    "results = np.empty((1, 9))\n",
    "\n",
    "# Log-Transform the AMS Data for LP-III Fitting\n",
    "sampling = np.log10(ams_hist)\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelpe3(mom)  # Fit LP-III Parameters\n",
    "\n",
    "# Compute Return Values Using LP-III Distribution\n",
    "returns = rlmom.quape3(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = 10 ** np.array(returns)  # Convert back from log-space\n",
    "results[0, 6:] = par  # Store LP-III parameters\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "os.makedirs('./results', exist_ok=True)  # Ensure the directory exists\n",
    "with open('./results/hist-lpe3.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"LP-III distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf9f43-733e-4f67-b099-214524ac038f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (PE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5db47c-076c-4c66-91bc-8c735c922aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to store results\n",
    "results = np.empty((1, 9))\n",
    "\n",
    "# Use the original AMS values (without log transformation)\n",
    "sampling = np.array(ams_hist)\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelpe3(mom)  # Fit PE3 Parameters\n",
    "\n",
    "# Compute Return Values Using PE3 Distribution\n",
    "returns = rlmom.quape3(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = np.array(returns)  # Store return levels\n",
    "results[0, 6:] = par  # Store PE3 parameters\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "with open('./results/hist-pe3.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"PE3 distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe36299-abbf-462a-8625-b37d177d1478",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (GEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5a2db-9124-48c9-a685-e7634dc60a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to store results\n",
    "results = np.empty((1, 9))\n",
    "\n",
    "# Use the original AMS values (without log transformation)\n",
    "sampling = np.array(ams_hist)\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelgev(mom)  # Fit GEV Parameters\n",
    "\n",
    "# Compute Return Values Using GEV Distribution\n",
    "returns = rlmom.quagev(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = np.array(returns)  # Store return levels\n",
    "results[0, 6:] = par  # Store GEV parameters\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "with open('./results/hist-gev.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"GEV distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d69fc-eb44-4275-84a3-7f702bbbda67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (LN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5080bbf-bb83-4797-9f87-4f624b7f99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to store results\n",
    "results = np.empty((1, 9))\n",
    "\n",
    "# Log-transform AMS data for LN3 fitting\n",
    "sampling = np.log(np.array(ams_hist))\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelln3(mom, bound=0)  # Fit LN3 Parameters\n",
    "\n",
    "# Compute Return Values Using LN3 Distribution\n",
    "returns = rlmom.qualn3(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = np.exp(np.array(returns))  # Convert back from log-space\n",
    "results[0, 6:] = par  # Store LN3 parameters\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "with open('./results/hist-ln3.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"LN3 distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901bd2ec-2e06-4947-8dda-3f12c1f7a37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (GPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138b757-14b0-4c29-8d57-7e439b688d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty array to store results\n",
    "results = np.empty((1, 9))\n",
    "\n",
    "# Use the original AMS values (without log transformation)\n",
    "sampling = np.array(ams_hist)\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelgpa(mom)  # Fit GPA Parameters\n",
    "\n",
    "# Compute Return Values Using GPA Distribution\n",
    "returns = rlmom.quagpa(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = np.array(returns)  # Store return levels\n",
    "results[0, 6:] = par  # Store GPA parameters\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "with open('./results/hist-gpa.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"GPA distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad2627-8d95-4968-bf45-5155db97ca50",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (Gumbel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f24c8-344f-4b9f-9a13-03bf2bc3f1d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty array to store results\n",
    "results = np.empty((1, 8))\n",
    "\n",
    "# Use the original AMS values (without log transformation)\n",
    "sampling = np.array(ams_hist)\n",
    "\n",
    "# Define the Return Periods (5, 10, 25, 50, 100, 200 years)\n",
    "F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "# Compute L-Moments Using R's `lmom` Package\n",
    "mom = rlmom.samlmu(ro.FloatVector(sampling))  # Sample L-moments\n",
    "par = rlmom.pelgum(mom)  # Fit Gumbel (GUM) Parameters\n",
    "\n",
    "# Compute Return Values Using Gumbel Distribution\n",
    "returns = rlmom.quagum(ro.FloatVector(F), par)\n",
    "\n",
    "# Store Results in Array\n",
    "results[0, :6] = np.array(returns)  # Store return levels\n",
    "results[0, 6:] = par  # Store Gumbel parameters\n",
    "\n",
    "# Ensure the results directory exists\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save Results to a `.npy` File\n",
    "with open('./results/hist-gum.npy', 'wb') as f:\n",
    "    np.save(f, results)\n",
    "\n",
    "print(\"Gumbel distribution for observed AMS processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b0d3a-e524-4d44-a645-76d9942cf7cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0828ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Font and figure settings\n",
    "XSMALL_SIZE = 8\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE, labelsize=MEDIUM_SIZE)\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE, facecolor='white', dpi=300)\n",
    "\n",
    "# Create a 1-row, 2-column subplot\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, dpi=300, figsize=(5 * 5, 4.3 * 2))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.2)  # Adjust spacing between plots\n",
    "\n",
    "# Scenario labels\n",
    "scn_labels = ['SSP2', 'SSP5']\n",
    "scenarios = ['4.5', '8.5']\n",
    "\n",
    "# Load the results from the saved .npy files\n",
    "hist_lpe3 = np.load('./results/hist-lpe3.npy')\n",
    "hist_pe3 = np.load('./results/hist-pe3.npy')\n",
    "hist_gev = np.load('./results/hist-gev.npy')\n",
    "hist_ln3 = np.load('./results/hist-ln3.npy')\n",
    "hist_gpa = np.load('./results/hist-gpa.npy')\n",
    "hist_gum = np.load('./results/hist-gum.npy')\n",
    "\n",
    "# Find the min and max values across all datasets for consistent y-axis scaling\n",
    "ymin = np.min([np.min(hist_lpe3[:, :6]), np.min(hist_pe3[:, :6]), np.min(hist_gev[:, :6]), \n",
    "               np.min(hist_ln3[:, :6]), np.min(hist_gpa[:, :6]), np.min(hist_gum[:, :6])])\n",
    "ymax = np.max([np.max(hist_lpe3[:, :6]), np.max(hist_pe3[:, :6]), np.max(hist_gev[:, :6]), \n",
    "               np.max(hist_ln3[:, :6]), np.max(hist_gpa[:, :6]), np.max(hist_gum[:, :6])])\n",
    "\n",
    "# Loop through each scenario and plot the data\n",
    "for sc_i, sc in enumerate(scenarios):\n",
    "    ax = axes[sc_i]\n",
    "\n",
    "    ax.plot([5,10,25,50,100,200], hist_lpe3[0, :6], color='red', linestyle='-', linewidth=3, label='Observed Data (LogP-III)')\n",
    "    ax.plot([5,10,25,50,100,200], hist_pe3[0, :6], color='orange', linestyle='dotted', linewidth=3, label='Observed Data (P-III)')\n",
    "    ax.plot([5,10,25,50,100,200], hist_gev[0, :6], color='blue', linestyle='-', linewidth=3, label='Observed Data (GEV)')\n",
    "    ax.plot([5,10,25,50,100,200], hist_ln3[0, :6], color='green', linestyle='-', linewidth=3, label='Observed Data (LN3)')\n",
    "    ax.plot([5,10,25,50,100,200], hist_gpa[0, :6], color='black', linestyle='dotted', linewidth=3, label='Observed Data (GPA)')\n",
    "    ax.plot([5,10,25,50,100,200], hist_gum[0, :6], color='magenta', linestyle='-', linewidth=3, label='Observed Data (Gumbel)')\n",
    "    \n",
    "    ax.set_title('Frequency analysis\\nObserved Data (1984-2016)')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xscale('log')  # Set x-axis to logarithmic scale\n",
    "    ax.set_xticks([5, 10, 25, 50, 100, 200])\n",
    "    ax.set_xticklabels([5, 10, 25, 50, 100, 200])  # Set labels for xticks\n",
    "    ax.set_xlim((5, 200))\n",
    "    ax.yaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    \n",
    "    if sc_i == 0:\n",
    "        ax.set_ylabel('streamflow [$m^3/s$]')\n",
    "        \n",
    "    ax.set_xlabel('Return Period [years]')\n",
    "    ax.grid(True, which=\"both\", linestyle=\"--\", alpha=0.5)\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "\n",
    "# Ensure results directory exists before saving\n",
    "import os\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('./results/return_periods_hist.jpg', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbb74e-be53-46b6-8094-0374a47313e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Applying the Best-Fit Distribution to Future AMS Projections**\n",
    "#### **Overview**\n",
    "Once the **best-fitting probability distribution** is identified from the historical AMS data, it is applied to **future climate projections** under the **SSP2-4.5 and SSP5-8.5 scenarios**. This step ensures that the selected distribution is used consistently across both historical and future datasets.\n",
    "\n",
    "A **random sampling approach** is employed to **account for model uncertainty** in future AMS projections, ensuring robust return period estimates.\n",
    "\n",
    "\n",
    "#### **Steps Performed**\n",
    "1. **Apply the Best-Fit Distribution to Historical AMS**\n",
    "   - Uses the previously identified **best-fit distribution**.\n",
    "   - Computes return period estimates for the **historical dataset**.\n",
    "   - Ensures consistency between historical and future analysis.\n",
    "\n",
    "2. **Load and Preprocess Future AMS Projections**\n",
    "   - Reads **future AMS datasets** for the **SSP2-4.5 and SSP5-8.5 scenarios**.\n",
    "   - Converts **\"Year\"** column to datetime format and sets it as an index.\n",
    "   - Extracts AMS values from **multiple climate models**.\n",
    "\n",
    "3. **Perform Random Sampling for Uncertainty Estimation**\n",
    "   - Uses **random sampling from three models** per scenario.\n",
    "   - Generates **1000 bootstrap samples** per climate scenario.\n",
    "   - Fits the **best-fit distribution** to each sample.\n",
    "\n",
    "4. **Compute Return Period Estimates for Future Scenarios**\n",
    "   - Computes **5th, 50th (median), and 95th percentile** return periods for each future scenario.\n",
    "   - Ensures that projections align with **historical trends**.\n",
    "\n",
    "5. **Save Results for Visualization and Further Analysis**\n",
    "   - Stores computed return period estimates for each scenario.\n",
    "   - Saves results in a structured format for **plotting and comparison**.\n",
    "\n",
    "\n",
    "\n",
    "#### **Instructions for Use**\n",
    "- Ensure that the best-fit distribution identified from historical AMS data is correctly applied.\n",
    "- Verify that future AMS datasets follow the **same structure as historical data**.\n",
    "- Modify the number of bootstrap samples (`1000` by default) if needed.\n",
    "\n",
    "\n",
    "\n",
    "#### **Expected Output**\n",
    "- **Future AMS return period estimates** using the best-fit distribution.\n",
    "- **Bootstrap samples** for model uncertainty analysis.\n",
    "- **Statistical outputs stored for visualization** in the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bce84-8407-417e-af9b-6bec899e055e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L-Moments (LogPearson-III) with random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca76ef-123c-41d8-b954-eaa601c47884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Load R's lmom package\n",
    "rlmom = importr('lmom')\n",
    "\n",
    "# Define the base path where the CSV files are stored\n",
    "path = r'E:/Projection_SWAT/ScenarioSs_SWAT_/AMS_Final'\n",
    "\n",
    "# Define scenario mappings to match filenames\n",
    "scenarios = {'4.5': 'ssp245', '8.5': 'ssp585'}\n",
    "\n",
    "for sc_i, (sc, ssp) in enumerate(scenarios.items()):\n",
    "    # Read files and set 'Year' column as index\n",
    "    access = pd.read_csv(f\"{path}/ACCESS-ESM1-5_{ssp}.csv\")\n",
    "    access['Year'] = pd.to_datetime(access['Year'], format='%Y')\n",
    "    access = access.set_index('Year')\n",
    "\n",
    "    if sc == '4.5':\n",
    "        mpi_esmi = pd.read_csv(f\"{path}/MPI-ESM1-2-HR_{ssp}.csv\")\n",
    "        mpi_esmi['Year'] = pd.to_datetime(mpi_esmi['Year'], format='%Y')\n",
    "        mpi_esmi = mpi_esmi.set_index('Year')\n",
    "    else:\n",
    "        giss = pd.read_csv(f\"{path}/GISS-E2-1-G_{ssp}.csv\")\n",
    "        giss['Year'] = pd.to_datetime(giss['Year'], format='%Y')\n",
    "        giss = giss.set_index('Year')\n",
    "\n",
    "    cnrm = pd.read_csv(f\"{path}/CNRM-ESM2-1_{ssp}.csv\")\n",
    "    cnrm['Year'] = pd.to_datetime(cnrm['Year'], format='%Y')\n",
    "    cnrm = cnrm.set_index('Year')\n",
    "\n",
    "    if sc == '4.5':\n",
    "        print(sc, access.columns, mpi_esmi.columns, cnrm.columns)\n",
    "        ams_pool = access[['AMS']].join(mpi_esmi[['AMS']], rsuffix='_mpi_esmi').join(cnrm[['AMS']], rsuffix='_cnrm')\n",
    "    else:\n",
    "        print(sc, access.columns, giss.columns, cnrm.columns)\n",
    "        ams_pool = access[['AMS']].join(giss[['AMS']], rsuffix='_giss').join(cnrm[['AMS']], rsuffix='_cnrm')\n",
    "\n",
    "    # Reshape dataset to (75, 3) for random sampling\n",
    "    ams_pool = ams_pool.values.reshape(75, 3)\n",
    "\n",
    "    # Create empty array for results (1000 simulations x 9 columns)\n",
    "    results = np.empty((1000, 9))\n",
    "\n",
    "    # Set up random number generator\n",
    "    rng = np.random.default_rng(int('10%03d' % sc_i))  # Better randomness control\n",
    "\n",
    "    # Perform 1000 iterations for random sampling\n",
    "    for sim in range(1000):\n",
    "        # Generate random indices for sampling 75 values from 3 models\n",
    "        indices = rng.integers(low=0, high=3, size=75)\n",
    "\n",
    "        # Extract randomly sampled AMS values\n",
    "        sampling = np.log10(np.array([ams_pool[i, model] for i, model in enumerate(indices)]))\n",
    "\n",
    "        # Define return periods\n",
    "        F = np.array([1 - (1/x) for x in [5, 10, 25, 50, 100, 200]])\n",
    "\n",
    "        # Compute L-Moments and fit Log-Pearson III (LP-III) parameters\n",
    "        mom = rlmom.samlmu(ro.FloatVector(sampling))\n",
    "        par = rlmom.pelpe3(mom)\n",
    "        returns = rlmom.quape3(ro.FloatVector(F), par)\n",
    "\n",
    "        # Store results\n",
    "        results[sim, :6] = 10 ** np.array(returns)  # Convert back from log-space\n",
    "        results[sim, 6:] = par  # Store LP-III parameters\n",
    "\n",
    "    # Ensure results directory exists\n",
    "    os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "    # Save results to `.npy` file\n",
    "    with open(f'./results/{sc}-fut-sim-lpe3.npy', 'wb') as f:\n",
    "        np.save(f, results)\n",
    "\n",
    "    print(f\"Scenario {sc}: Future simulations processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0eb9b-3df1-436e-bb9c-1da5256a8242",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bff08-95db-41dc-a5f6-93b2e134b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font and figure settings\n",
    "XSMALL_SIZE = 8\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 17\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE, labelsize=BIGGER_SIZE)\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE, facecolor='white', dpi=300)\n",
    "\n",
    "# Create a 1-row, 2-column subplot\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, dpi=300, figsize=(5 * 5, 4.3 * 2))\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.15)\n",
    "\n",
    "# Load historical observed data\n",
    "hist_lpe3 = np.load('./results/hist-lpe3.npy')\n",
    "\n",
    "# Define scenario labels and mappings\n",
    "scn_labels = ['SSP2', 'SSP5']\n",
    "scenarios = ['4.5', '8.5']\n",
    "\n",
    "# Loop through each scenario and plot the simulations\n",
    "for sc_i, sc in enumerate(scenarios):\n",
    "    \n",
    "    # Load future simulations\n",
    "    fut = np.load(f'./results/{sc}-fut-sim-lpe3.npy')  # Corrected file extension to `.npy`\n",
    "    \n",
    "    # Axis limits\n",
    "    ymin = 10000\n",
    "    ymax = np.max(fut[:, :6])\n",
    "    \n",
    "    simulations = fut\n",
    "    \n",
    "    ax = axes[sc_i]\n",
    "    \n",
    "    # Plot all simulations with transparency\n",
    "    for sim in simulations:\n",
    "        ax.plot([5,10,25,50,100,200], sim[:6], color='#889', alpha=0.1)\n",
    "    \n",
    "    # Plot the percentile-based confidence bounds\n",
    "    ax.plot([5,10,25,50,100,200], np.percentile(simulations[:, :6], 5, axis=0), color='blue', linestyle='--', linewidth=2, label='21st Century Low (5th)')\n",
    "    ax.plot([5,10,25,50,100,200], np.median(simulations[:, :6], axis=0), color='lightgreen', linestyle='--', linewidth=2, label='21st Century Median (50th)')\n",
    "    ax.plot([5,10,25,50,100,200], np.percentile(simulations[:, :6], 95, axis=0), color='red', linestyle='--', linewidth=2, label='21st Century High (95th)')\n",
    "    \n",
    "    # Plot observed historical data\n",
    "    ax.plot([5,10,25,50,100,200], hist_lpe3[0, :6], color='fuchsia', linestyle='-', linewidth=2, label='20th Century')\n",
    "    \n",
    "    ax.legend(loc='upper left')\n",
    "    \n",
    "    # Logarithmic x-axis\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks([5,10,25,50,100,200])\n",
    "    ax.set_xticklabels([5,10,25,50,100,200])\n",
    "    ax.set_xlim((5, 200))\n",
    "    \n",
    "    # Format y-axis\n",
    "    ax.yaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    \n",
    "    if sc_i == 0:\n",
    "        ax.set_ylabel(r'Streamflow ($\\bf{m^3/s}$)', weight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Return Period (Years)', weight='bold')\n",
    "    ax.grid()\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "    \n",
    "    # Add labels 'a' and 'b' inside each subplot\n",
    "    if sc_i == 0:\n",
    "        ax.text(0.95, 0.95, 'a', transform=ax.transAxes, fontsize=36, ha='center', va='center', weight='bold')\n",
    "    elif sc_i == 1:\n",
    "        ax.text(0.95, 0.95, 'b', transform=ax.transAxes, fontsize=36, ha='center', va='center', weight='bold')\n",
    "\n",
    "# Ensure results directory exists before saving\n",
    "import os\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Save the figure as a high-resolution SVG\n",
    "plt.savefig(r'D:/CMIP6-BiasCorrection-SWAT/workingfolder/Results_Plots/flow-grids-lpe3-Fig5.png', format=\"png\", bbox_inches='tight', dpi=600)\n",
    "# Save the figure as a high-resolution PDF\n",
    "#plt.savefig(r'D:/CMIP6-BiasCorrection-SWAT/workingfolder/Results_Plots/flow-grids-lpe3-Fig5.pdf', format=\"pdf\", bbox_inches='tight', dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySWATplus_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
