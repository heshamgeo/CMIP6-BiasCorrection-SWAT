{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Period Analysis and Bootstrap Uncertainty Intervals\n",
    "\n",
    "## Overview\n",
    "This script analyzes observed and model-based annual maximum series (AMS) for streamflow and fits probability distributions to estimate return periods. A bootstrap resampling approach is applied to generate Uncertainty intervals for future climate projections.\n",
    "\n",
    "## Steps Performed:\n",
    "\n",
    "1. **Setup & Configuration**\n",
    "   - Defines file paths for observed and modeled AMS data (csv format).\n",
    "   - Specifies probability distributions to test, including GEV, Gumbel, Weibull, and Pearson-III.\n",
    "\n",
    "2. **Fit Distributions to Observed Data**\n",
    "   - Reads observed AMS data.\n",
    "   - Fits multiple probability distributions and selects the best one using the Kolmogorov-Smirnov (KS) test.\n",
    "   - Computes return periods for the best-fit distribution.\n",
    "\n",
    "3. **Fit Distributions to Model Data**\n",
    "   - Iterates through climate model projections.\n",
    "   - Fits distributions to each dataset and selects the best fit.\n",
    "   - Stores AMS values for ensemble analysis.\n",
    "\n",
    "4. **Bootstrap Resampling for Uncertainty Estimation**\n",
    "   - Resamples AMS data using bootstrapping (1000 iterations).\n",
    "   - Fits the same distribution family as observed.\n",
    "   - Computes Uncertainty intervals (5th, 50th, and 95th percentiles) for return periods.\n",
    "\n",
    "5. **Plotting & Exporting**\n",
    "   - Plots return period curves for:\n",
    "     - **Historical observations** (20th century).\n",
    "     - **Future climate projections** (21st century, SSP scenarios).\n",
    "     - **Bootstrap confidence intervals** (shaded in gray).\n",
    "   - Saves the plot as an SVG file for high-quality output.\n",
    "\n",
    "## Instructions for Use:\n",
    "- Ensure that the observed and modeled AMS datasets are correctly formatted and stored in the specified directories.\n",
    "- Modify `model_files` to include additional climate models if needed.\n",
    "- Run the script to generate return period plots with confidence intervals.\n",
    "\n",
    "### Output:\n",
    "- A **return period curve plot** comparing historical and future projections.\n",
    "- An **SVG file** saved at the specified output location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import (genextreme, expon, genlogistic,\n",
    "                         genpareto, gamma, pearson3, weibull_min, invgamma, kstest)\n",
    "from scipy.stats import gumbel_r\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. SETUP: Paths, distributions\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "base_dir = r\"D:/CMIP6-BiasCorrection-SWAT/workingfolder/AMS_Final\"\n",
    "observed_file = f\"{base_dir}/observed_ams.csv\"\n",
    "model_files = [\n",
    "#    f\"{base_dir}/ACCESS-ESM1-5_ssp245.csv\",\n",
    "#    f\"{base_dir}/CNRM-ESM2-1_ssp245.csv\",\n",
    "#    f\"{base_dir}/MPI-ESM1-2-HR_ssp25.csv\"\n",
    "#]\n",
    "\n",
    "\n",
    "    f\"{base_dir}/ACCESS-ESM1-5_ssp585.csv\",\n",
    "    f\"{base_dir}/GISS-E2-1-G_ssp585.csv\",\n",
    "    f\"{base_dir}/CNRM-ESM2-1_ssp585.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "distributions = {\n",
    "    \"GEV\": genextreme,\n",
    "    \"EXP\": expon,\n",
    "    \"GLO\": genlogistic,\n",
    "    \"GPA\": genpareto,\n",
    "    \"GAM\": gamma,\n",
    "    \"PE3\": pearson3,\n",
    "    \"WEI\": weibull_min,\n",
    "    \"GUM\": gumbel_r,\n",
    "    \"PTV\": invgamma \n",
    "}\n",
    "\n",
    "n_boot = 1000\n",
    "# We want return periods from 5 to 200, for the PPF\n",
    "return_periods = np.linspace(5, 200, 100)\n",
    "cdf_vals = 1 - 1.0 / return_periods\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def fit_all_distributions(data, dists):\n",
    "    \"\"\"\n",
    "    Fit each distribution in 'dists' to 'data' and compute \n",
    "    the KS statistic. Return a dict: \n",
    "        { dist_name: (params, ks_stat), ... }\n",
    "    \"\"\"\n",
    "    fits = {}\n",
    "    for name, dist in dists.items():\n",
    "        try:\n",
    "            params = dist.fit(data)\n",
    "            ks_stat, _ = kstest(\n",
    "                data,\n",
    "                lambda x: dist.cdf(x, *params[:-2], loc=params[-2], scale=params[-1])\n",
    "            )\n",
    "            fits[name] = (params, ks_stat)\n",
    "        except:\n",
    "            # If fit fails, store None / infinite KS\n",
    "            fits[name] = (None, np.inf)\n",
    "    return fits\n",
    "\n",
    "def pick_best_distribution(fits_dict):\n",
    "    \"\"\"\n",
    "    From a dict of {dist_name: (params, ks_stat)}, pick \n",
    "    the one with the lowest KS stat.\n",
    "    \"\"\"\n",
    "    best_name = None\n",
    "    best_params = None\n",
    "    best_ks = np.inf\n",
    "    for dist_name, (params, ks_stat) in fits_dict.items():\n",
    "        if ks_stat < best_ks:\n",
    "            best_ks = ks_stat\n",
    "            best_name = dist_name\n",
    "            best_params = params\n",
    "    return best_name, best_params, best_ks\n",
    "\n",
    "def print_fit_results(label, fits_dict):\n",
    "    \"\"\"\n",
    "    Pretty-print the KS stats for all distributions, plus\n",
    "    highlight which is best.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{label}\")\n",
    "    best_name, _, best_ks = pick_best_distribution(fits_dict)\n",
    "    for dist_name, (params, ks_stat) in fits_dict.items():\n",
    "        if np.isfinite(ks_stat):\n",
    "            print(f\"   {dist_name:3} => KS={ks_stat:.4f}\")\n",
    "        else:\n",
    "            print(f\"   {dist_name:3} => Fit failed\")\n",
    "    print(f\"   BEST => {best_name} (KS={best_ks:.4f})\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. FIT OBSERVED\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "observed_df = pd.read_csv(observed_file)\n",
    "obs_data = observed_df[\"AMS\"]\n",
    "\n",
    "obs_fits = fit_all_distributions(obs_data, distributions)\n",
    "print_fit_results(\"Observed Data Fit Results:\", obs_fits)\n",
    "\n",
    "# Decide which distribution to use for Observed\n",
    "use_fit_choice_obs = \"BEST\"\n",
    "if use_fit_choice_obs == \"BEST\":\n",
    "    obs_dist_name, obs_dist_params, _ = pick_best_distribution(obs_fits)\n",
    "else:\n",
    "    obs_dist_name = use_fit_choice_obs\n",
    "    obs_dist_params, _ = obs_fits[obs_dist_name]\n",
    "\n",
    "obs_dist_obj = distributions[obs_dist_name]\n",
    "\n",
    "# Evaluate the observed return‐period curve\n",
    "obs_curve = obs_dist_obj.ppf(\n",
    "    cdf_vals, \n",
    "    *obs_dist_params[:-2],\n",
    "    loc=obs_dist_params[-2],\n",
    "    scale=obs_dist_params[-1]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. FIT MODEL DATA\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "model_datasets = []\n",
    "combined_ams = []\n",
    "\n",
    "for file in model_files:\n",
    "    df = pd.read_csv(file)\n",
    "    model_name = file.split(\"\\\\\")[-1]  # or some other ID\n",
    "\n",
    "    fits_dict = fit_all_distributions(df[\"AMS\"], distributions)\n",
    "    print_fit_results(f\"Model: {model_name}\", fits_dict)\n",
    "\n",
    "    # Decide which distribution to *use* for the final results\n",
    "    use_fit_choice = \"BEST\"\n",
    "    if use_fit_choice == \"BEST\":\n",
    "        best_name, best_params, _ = pick_best_distribution(fits_dict)\n",
    "        chosen_name = best_name\n",
    "        chosen_params = best_params\n",
    "    else:\n",
    "        chosen_name = use_fit_choice\n",
    "        chosen_params, _ = fits_dict[chosen_name]\n",
    "\n",
    "    model_datasets.append({\n",
    "        \"name\": model_name,\n",
    "        \"data\": df[\"AMS\"].values,\n",
    "        \"dist_name\": chosen_name,\n",
    "        \"dist_params\": chosen_params\n",
    "    })\n",
    "\n",
    "    # For ensemble, we just gather all AMS in combined_ams\n",
    "    combined_ams.append(df[\"AMS\"].values)\n",
    "\n",
    "combined_ams = np.concatenate(combined_ams)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. BOOTSTRAP (using Observed's distribution family)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "dist_obj = distributions[obs_dist_name]\n",
    "bootstrap_curves = []\n",
    "\n",
    "for _ in range(n_boot):\n",
    "    sample = np.random.choice(combined_ams, size=len(combined_ams), replace=True)\n",
    "    b_params = dist_obj.fit(sample)\n",
    "    curve = dist_obj.ppf(\n",
    "        cdf_vals,\n",
    "        *b_params[:-2],\n",
    "        loc=b_params[-2],\n",
    "        scale=b_params[-1]\n",
    "    )\n",
    "    bootstrap_curves.append(curve)\n",
    "\n",
    "bootstrap_curves = np.array(bootstrap_curves)\n",
    "low_curve  = np.percentile(bootstrap_curves, 5,  axis=0)\n",
    "med_curve  = np.percentile(bootstrap_curves, 50, axis=0)\n",
    "high_curve = np.percentile(bootstrap_curves, 95, axis=0)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. PLOTTING\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. PLOTTING AND EXPORTING TO SVG\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Plot each bootstrap in gray\n",
    "for i in range(n_boot):\n",
    "    plt.plot(return_periods, bootstrap_curves[i,:],\n",
    "             color='gray', alpha=0.2, linewidth=0.8)\n",
    "\n",
    "# Plot percentile summary lines\n",
    "plt.plot(return_periods, low_curve,  linestyle='--', color='blue',\n",
    "         label=\"21st Century Low (5th)\")\n",
    "plt.plot(return_periods, med_curve,  linestyle='-',  color='green',\n",
    "         label=\"21st Century Median (50th)\")\n",
    "plt.plot(return_periods, high_curve, linestyle='-.', color='red',\n",
    "         label=\"21st Century High (95th)\")\n",
    "\n",
    "# Observed\n",
    "plt.plot(return_periods, obs_curve, color='purple', linewidth=2,\n",
    "         label=\"20th Century\")\n",
    "\n",
    "# Set log scale on the x-axis, but fix ticks at 5,10,25,50,100,200\n",
    "plt.xscale('log')\n",
    "plt.xlim(5, 200)\n",
    "plt.xticks([5, 10, 25, 50, 100, 200],\n",
    "           ['5', '10', '25', '50', '100', '200'])\n",
    "\n",
    "plt.xlabel(\"Return Period (Years)\")\n",
    "plt.ylabel(\"Streamflow (m³/s)\")\n",
    "plt.title(\"Return Period Curves with 500 Bootstrap Samples (SSP2-4.5)\")\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to SVG format\n",
    "output_svg_path = r\"D:/CMIP6-BiasCorrection-SWAT/workingfolder/Results_Plots/ssp245_return_period.svg\"  #Example\n",
    "plt.savefig(output_svg_path, format=\"svg\", dpi=300)  # Save before showing the plot\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Notify that the SVG has been saved\n",
    "print(f\"Plot saved as SVG at: {output_svg_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySWATplus_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
