{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Correction Process\n",
    "\n",
    "This script performs **bias correction** for precipitation data from CMIP6 models using CHRIPS observed precipitation data. The process involves:\n",
    "\n",
    "### 1. Setting Up Directories\n",
    "- Define paths for standardized **CMIP6 model data**, **CHRIPS observed data**, and **output files**.\n",
    "- Ensure that all required datasets are stored in the correct directory structure.\n",
    "\n",
    "### 2. Loading Calibration Data\n",
    "- Load observed precipitation data (`CHIRPS`) and CMIP6 model data for the overlapping period (2015–2025).\n",
    "- Standardize the time format and **align observed data to the model grid** for consistency.\n",
    "\n",
    "### 3. Computing Quantiles\n",
    "- Compute **quantiles** for both observed and model precipitation data to establish a correction relationship.\n",
    "\n",
    "### 4. Applying Bias Correction (Quantile Mapping)\n",
    "- Apply **quantile mapping** to adjust model precipitation data using the computed quantiles.\n",
    "- Save **bias-corrected calibration data** for the overlapping period (2015-2025).\n",
    "\n",
    "### 5. Processing Future Projections (2025–2100)\n",
    "- Load **future CMIP6 model data** for the specified scenarios.\n",
    "- Apply the **same quantile mapping** to adjust future precipitation projections.\n",
    "- Save the **bias-corrected future data**.\n",
    "\n",
    "### Instructions for Use\n",
    "1. Ensure that **standardized CMIP6 data and CHRIPS observed data** exist in the specified directories.\n",
    "2. Run the script, and it will:\n",
    "   - Identify the available models and scenarios.\n",
    "   - Perform **bias correction using quantile mapping**.\n",
    "   - Save the corrected outputs in the designated output folder.\n",
    "\n",
    "### Final Output\n",
    "- Bias-corrected precipitation data for both:\n",
    "  - **Calibration period (2015–2025)**.\n",
    "  - **Future projections (2025–2100)**.\n",
    "- All corrected data is stored in the **output directory**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === Define your base paths here ===\n",
    "base_dir = r\"D:/CMIP6-BiasCorrection-SWAT/workingfolder/standardized_data/\"\n",
    "observed_base_dir = r\"D:/CMIP6-BiasCorrection-SWAT/workingfolder/observed/\"\n",
    "output_dir = r\"D:/CMIP6-BiasCorrection-SWAT/workingfolder/bias_corrected/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define calibration and future years\n",
    "calibration_years = range(2015, 2025)\n",
    "future_years = range(2025, 2101)\n",
    "\n",
    "# === Observed data parameters ===\n",
    "# If your observed data follows a different pattern, adjust here\n",
    "observed_pattern = \"clipped_chirps-v2.0.{year}.days_p25.nc\"\n",
    "observed_variable = \"precip\"\n",
    "\n",
    "# Function to standardize time\n",
    "def standardize_time(ds):\n",
    "    \"\"\"Converts time to np.datetime64 if needed.\"\"\"\n",
    "    if not np.issubdtype(ds[\"time\"].dtype, np.datetime64):\n",
    "        ds[\"time\"] = xr.cftime_range(\n",
    "            start=str(ds[\"time\"].values[0]), periods=len(ds[\"time\"]), freq=\"D\"\n",
    "        ).to_datetimeindex()\n",
    "    return ds\n",
    "\n",
    "# Function to standardize observed data dimensions\n",
    "def standardize_observed(observed_ds, model_ds):\n",
    "    \"\"\"\n",
    "    Renames the y/x dims in observed data to lat/lon\n",
    "    and interpolates them onto the model grid.\n",
    "    \"\"\"\n",
    "    observed_ds = observed_ds.rename({\"y\": \"lat\", \"x\": \"lon\"})\n",
    "    observed_ds = observed_ds.interp(\n",
    "        lat=model_ds[\"lat\"], lon=model_ds[\"lon\"], method=\"linear\"\n",
    "    )\n",
    "    return observed_ds\n",
    "\n",
    "# Loop through models and scenarios in the base directory\n",
    "for model in os.listdir(base_dir):\n",
    "    model_path = os.path.join(base_dir, model)\n",
    "    if not os.path.isdir(model_path) or model == \"observed\":\n",
    "        # Skip non-directories and the 'observed' folder itself\n",
    "        continue\n",
    "    \n",
    "    for scenario in [\"ssp245\", \"ssp585\"]:\n",
    "        scenario_path = os.path.join(model_path, scenario, \"pr\")\n",
    "        if not os.path.exists(scenario_path):\n",
    "            continue  # Skip if scenario folder doesn't exist\n",
    "        \n",
    "        print(f\"Processing Model: {model}, Scenario: {scenario}\")\n",
    "        \n",
    "        # Create an output directory for each scenario\n",
    "        scenario_output_dir = os.path.join(output_dir, model, scenario)\n",
    "        os.makedirs(scenario_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Prepare lists to collect observed and model data for calibration\n",
    "        observed_list = []\n",
    "        model_list = []\n",
    "\n",
    "        # === Load calibration data ===\n",
    "        for year in calibration_years:\n",
    "            # Observed file\n",
    "            obs_file = os.path.join(observed_base_dir, observed_pattern.format(year=year))\n",
    "            \n",
    "            # Model files matching your dynamic pattern:\n",
    "            # e.g. pr_day_{model}_{scenario}_{pattern}_{year}_{version}_clipped.nc\n",
    "            mod_files = glob.glob(\n",
    "                os.path.join(scenario_path, f\"pr_day_{model}_{scenario}_*_{year}_*_clipped.nc\")\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(obs_file) or len(mod_files) == 0:\n",
    "                print(f\"Missing data for year {year} (observed or model), skipping...\")\n",
    "                continue\n",
    "            \n",
    "            mod_file = mod_files[0]  # If multiple, pick the first or handle as needed\n",
    "            \n",
    "            # Open datasets\n",
    "            obs_ds = xr.open_dataset(obs_file)\n",
    "            mod_ds = xr.open_dataset(mod_file)\n",
    "            \n",
    "            obs_ds = standardize_time(obs_ds)\n",
    "            mod_ds = standardize_time(mod_ds)\n",
    "            \n",
    "            # Interpolate observed onto model grid\n",
    "            obs_ds = standardize_observed(obs_ds, mod_ds)\n",
    "            \n",
    "            # Append the data arrays for calibration\n",
    "            observed_list.append(obs_ds[observed_variable])\n",
    "            model_list.append(mod_ds[\"pr\"])\n",
    "\n",
    "        # If no calibration data found, skip to the next scenario\n",
    "        if len(observed_list) == 0 or len(model_list) == 0:\n",
    "            print(\"No valid calibration data found. Skipping this scenario...\")\n",
    "            continue\n",
    "\n",
    "        # Concatenate observed and model data over the calibration period\n",
    "        observed_data = xr.concat(observed_list, dim=\"time\")\n",
    "        model_data = xr.concat(model_list, dim=\"time\")\n",
    "\n",
    "        # Compute quantiles\n",
    "        print(\"Calculating quantiles...\")\n",
    "        quantiles = np.linspace(0, 1, 1001)\n",
    "        observed_quantiles = observed_data.quantile(quantiles, dim=\"time\")\n",
    "        model_quantiles = model_data.quantile(quantiles, dim=\"time\")\n",
    "\n",
    "        # === Save bias-corrected calibration data ===\n",
    "        print(\"Saving bias-corrected calibration data...\")\n",
    "        # We assume the order of 'model_list' corresponds to the order of calibration years\n",
    "        # If some years were skipped, track them carefully\n",
    "        used_calibration_years = calibration_years\n",
    "        for year, mod_data in zip(used_calibration_years, model_list):\n",
    "            # Flatten so we can apply np.interp\n",
    "            mod_data_flat = mod_data.stack(z=(\"lat\", \"lon\"))\n",
    "            model_quantiles_flat = model_quantiles.stack(z=(\"lat\", \"lon\"))\n",
    "            observed_quantiles_flat = observed_quantiles.stack(z=(\"lat\", \"lon\"))\n",
    "            \n",
    "            corrected_calibration_flat = xr.apply_ufunc(\n",
    "                np.interp,\n",
    "                mod_data_flat,\n",
    "                model_quantiles_flat,\n",
    "                observed_quantiles_flat,\n",
    "                input_core_dims=[[\"time\"], [\"quantile\"], [\"quantile\"]],\n",
    "                output_core_dims=[[\"time\"]],\n",
    "                vectorize=True,\n",
    "                dask=\"parallelized\",\n",
    "                output_dtypes=[mod_data.dtype],\n",
    "            )\n",
    "            \n",
    "            corrected_calibration = corrected_calibration_flat.unstack(\"z\")\n",
    "            calibration_ds = xr.Dataset({\"pr\": corrected_calibration})\n",
    "            \n",
    "            output_file_calibration = os.path.join(\n",
    "                scenario_output_dir, f\"bias_corrected_{model}_{scenario}_{year}_calibration.nc\"\n",
    "            )\n",
    "            calibration_ds.to_netcdf(output_file_calibration)\n",
    "            print(f\"Bias-corrected calibration data saved for {year}: {output_file_calibration}\")\n",
    "\n",
    "        # === Process future data ===\n",
    "        print(\"Processing future data...\")\n",
    "        for year in future_years:\n",
    "            future_files = glob.glob(\n",
    "                os.path.join(scenario_path, f\"pr_day_{model}_{scenario}_*_{year}_*_clipped.nc\")\n",
    "            )\n",
    "            if len(future_files) == 0:\n",
    "                print(f\"No future model file for {year}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            future_file = future_files[0]  # If multiple, pick first\n",
    "            future_ds = xr.open_dataset(future_file)\n",
    "            future_ds = standardize_time(future_ds)\n",
    "            \n",
    "            # Flatten future data for quantile mapping\n",
    "            future_data = future_ds[\"pr\"]\n",
    "            future_data_flat = future_data.stack(z=(\"lat\", \"lon\"))\n",
    "            \n",
    "            model_quantiles_flat = model_quantiles.stack(z=(\"lat\", \"lon\"))\n",
    "            observed_quantiles_flat = observed_quantiles.stack(z=(\"lat\", \"lon\"))\n",
    "\n",
    "            corrected_data_flat = xr.apply_ufunc(\n",
    "                np.interp,\n",
    "                future_data_flat,\n",
    "                model_quantiles_flat,\n",
    "                observed_quantiles_flat,\n",
    "                input_core_dims=[[\"time\"], [\"quantile\"], [\"quantile\"]],\n",
    "                output_core_dims=[[\"time\"]],\n",
    "                vectorize=True,\n",
    "                dask=\"parallelized\",\n",
    "                output_dtypes=[future_data.dtype],\n",
    "            )\n",
    "\n",
    "            corrected_data = corrected_data_flat.unstack(\"z\")\n",
    "            future_ds[\"pr\"] = corrected_data\n",
    "\n",
    "            output_file_future = os.path.join(\n",
    "                scenario_output_dir, f\"bias_corrected_{model}_{scenario}_{year}.nc\"\n",
    "            )\n",
    "            future_ds.to_netcdf(output_file_future)\n",
    "            print(f\"Bias-corrected future data saved for {year}: {output_file_future}\")\n",
    "\n",
    "print(\"Processing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySWATplus_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
